{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7866130,"sourceType":"datasetVersion","datasetId":4614939},{"sourceId":17194,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":14320}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"json\", data_files=\"/kaggle/input/news-data/news_data.json\", split=\"train\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T21:20:47.303118Z","iopub.execute_input":"2024-03-17T21:20:47.303560Z","iopub.status.idle":"2024-03-17T21:20:50.491650Z","shell.execute_reply.started":"2024-03-17T21:20:47.303516Z","shell.execute_reply":"2024-03-17T21:20:50.490623Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-89a6eda3f631cd3b/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"459650e5166842e4bada714d9fd6686a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0b9260a519d442ebf4c2581c83cc23b"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-89a6eda3f631cd3b/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:20:50.493406Z","iopub.execute_input":"2024-03-17T21:20:50.493890Z","iopub.status.idle":"2024-03-17T21:20:56.039787Z","shell.execute_reply.started":"2024-03-17T21:20:50.493853Z","shell.execute_reply":"2024-03-17T21:20:56.038788Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T19:03:50.911755Z","iopub.execute_input":"2024-03-17T19:03:50.912278Z","iopub.status.idle":"2024-03-17T19:03:51.015574Z","shell.execute_reply.started":"2024-03-17T19:03:50.912250Z","shell.execute_reply":"2024-03-17T19:03:51.014341Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:20:56.041623Z","iopub.execute_input":"2024-03-17T21:20:56.042074Z","iopub.status.idle":"2024-03-17T21:20:56.095623Z","shell.execute_reply.started":"2024-03-17T21:20:56.042048Z","shell.execute_reply":"2024-03-17T21:20:56.094578Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"! pip install -U accelerate\n! pip install -U transformers","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:21:01.697768Z","iopub.execute_input":"2024-03-17T21:21:01.698441Z","iopub.status.idle":"2024-03-17T21:21:10.214511Z","shell.execute_reply.started":"2024-03-17T21:21:01.698406Z","shell.execute_reply":"2024-03-17T21:21:10.213327Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nCollecting transformers\n  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# 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\nfrom huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:21:17.555912Z","iopub.execute_input":"2024-03-17T21:21:17.556329Z","iopub.status.idle":"2024-03-17T21:21:17.588154Z","shell.execute_reply.started":"2024-03-17T21:21:17.556293Z","shell.execute_reply":"2024-03-17T21:21:17.587263Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22f11f46ea9e44e78a1cd325b81955e5"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:21:25.922486Z","iopub.execute_input":"2024-03-17T21:21:25.923429Z","iopub.status.idle":"2024-03-17T21:21:25.945756Z","shell.execute_reply.started":"2024-03-17T21:21:25.923390Z","shell.execute_reply":"2024-03-17T21:21:25.944814Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-17T19:04:13.378257Z","iopub.execute_input":"2024-03-17T19:04:13.378785Z","iopub.status.idle":"2024-03-17T19:04:13.385370Z","shell.execute_reply.started":"2024-03-17T19:04:13.378755Z","shell.execute_reply":"2024-03-17T19:04:13.384400Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 24\n    })\n    test: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 6\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"/kaggle/input/mbart_ru_sum_gazeta/pytorch/mbart_ru_sum_gazeta/1\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:21:29.803731Z","iopub.execute_input":"2024-03-17T21:21:29.804147Z","iopub.status.idle":"2024-03-17T21:21:36.311364Z","shell.execute_reply.started":"2024-03-17T21:21:29.804118Z","shell.execute_reply":"2024-03-17T21:21:36.310373Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example[\"text\"], example[\"summary\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:21:36.313380Z","iopub.execute_input":"2024-03-17T21:21:36.314069Z","iopub.status.idle":"2024-03-17T21:21:36.319749Z","shell.execute_reply.started":"2024-03-17T21:21:36.314029Z","shell.execute_reply":"2024-03-17T21:21:36.318530Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"max_input_length = 2048\nmax_target_length = 2048\n\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"text\"],\n        max_length=max_input_length,\n        truncation=True,\n    )\n    labels = tokenizer(\n        examples[\"summary\"], max_length=max_target_length, truncation=True\n    )\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:21:50.695390Z","iopub.execute_input":"2024-03-17T21:21:50.696065Z","iopub.status.idle":"2024-03-17T21:21:50.701704Z","shell.execute_reply.started":"2024-03-17T21:21:50.696031Z","shell.execute_reply":"2024-03-17T21:21:50.700577Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = dataset.map(preprocess_function, batched=True)\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:21:53.659318Z","iopub.execute_input":"2024-03-17T21:21:53.660107Z","iopub.status.idle":"2024-03-17T21:21:53.810393Z","shell.execute_reply.started":"2024-03-17T21:21:53.660077Z","shell.execute_reply":"2024-03-17T21:21:53.809459Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f017649f62f04e99acc07dac0ebd7c73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"539cbf219b554219b1ab0dc770d61d13"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 24\n    })\n    test: Dataset({\n        features: ['text', 'summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 6\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:21:56.704229Z","iopub.execute_input":"2024-03-17T21:21:56.704594Z","iopub.status.idle":"2024-03-17T21:22:12.428403Z","shell.execute_reply.started":"2024-03-17T21:21:56.704566Z","shell.execute_reply":"2024-03-17T21:22:12.427214Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=0ded395c5013eb1c7684f7721be5e1d888dbee9ebacbbe4eeb8bba6372e51e7c\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"TOKENIZERS_PARALLELISM=False","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:22:12.430407Z","iopub.execute_input":"2024-03-17T21:22:12.430734Z","iopub.status.idle":"2024-03-17T21:22:12.435535Z","shell.execute_reply.started":"2024-03-17T21:22:12.430704Z","shell.execute_reply":"2024-03-17T21:22:12.434556Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:22:12.436808Z","iopub.execute_input":"2024-03-17T21:22:12.437170Z","iopub.status.idle":"2024-03-17T21:22:25.458407Z","shell.execute_reply.started":"2024-03-17T21:22:12.437138Z","shell.execute_reply":"2024-03-17T21:22:25.457247Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m820.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nrouge_score = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:22:25.461313Z","iopub.execute_input":"2024-03-17T21:22:25.461726Z","iopub.status.idle":"2024-03-17T21:22:47.964609Z","shell.execute_reply.started":"2024-03-17T21:22:25.461686Z","shell.execute_reply":"2024-03-17T21:22:47.963724Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2024-03-17 21:22:29.562988: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-17 21:22:29.563086: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-17 21:22:29.854631: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"218ed5e73ad94de4b6b664d31972e4f4"}},"metadata":{}}]},{"cell_type":"code","source":"pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:22:47.966000Z","iopub.execute_input":"2024-03-17T21:22:47.967118Z","iopub.status.idle":"2024-03-17T21:23:00.172208Z","shell.execute_reply.started":"2024-03-17T21:22:47.967081Z","shell.execute_reply":"2024-03-17T21:23:00.170987Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\n\nnltk.download(\"punkt\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:23:00.173854Z","iopub.execute_input":"2024-03-17T21:23:00.174180Z","iopub.status.idle":"2024-03-17T21:23:00.698896Z","shell.execute_reply.started":"2024-03-17T21:23:00.174150Z","shell.execute_reply":"2024-03-17T21:23:00.697957Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:23:33.228497Z","iopub.execute_input":"2024-03-17T21:23:33.228892Z","iopub.status.idle":"2024-03-17T21:24:06.008636Z","shell.execute_reply.started":"2024-03-17T21:23:33.228864Z","shell.execute_reply":"2024-03-17T21:24:06.007765Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import accelerate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install psutil","metadata":{"execution":{"iopub.status.busy":"2024-03-17T18:02:30.038268Z","iopub.execute_input":"2024-03-17T18:02:30.039203Z","iopub.status.idle":"2024-03-17T18:02:42.425854Z","shell.execute_reply.started":"2024-03-17T18:02:30.039168Z","shell.execute_reply":"2024-03-17T18:02:42.424597Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (5.9.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\nbatch_size = 3\nnum_train_epochs = 2\n# Show the training loss with every epoch\nlogging_steps = len(tokenized_datasets[\"train\"]) // batch_size\nmodel_name = checkpoint.split(\"/\")[-1]\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=f\"{model_name}-finetuned-mbart_ru_sum_gazeta\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=5.6e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=num_train_epochs,\n    predict_with_generate=True,\n    logging_steps=logging_steps,\n    push_to_hub=False,\n    use_cpu=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:46:35.247753Z","iopub.execute_input":"2024-03-17T21:46:35.248565Z","iopub.status.idle":"2024-03-17T21:46:35.261393Z","shell.execute_reply.started":"2024-03-17T21:46:35.248530Z","shell.execute_reply":"2024-03-17T21:46:35.260276Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from nltk import sent_tokenize","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:24:56.214547Z","iopub.execute_input":"2024-03-17T21:24:56.214890Z","iopub.status.idle":"2024-03-17T21:24:56.219092Z","shell.execute_reply.started":"2024-03-17T21:24:56.214866Z","shell.execute_reply":"2024-03-17T21:24:56.218107Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    # Decode generated summaries into text\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    # Decode reference summaries into text\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # ROUGE expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n    # Compute ROUGE scores\n    result = rouge_score.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract the median scores\n    result = {key: value * 100 for key, value in result.items()}\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:24:57.613082Z","iopub.execute_input":"2024-03-17T21:24:57.614012Z","iopub.status.idle":"2024-03-17T21:24:57.622605Z","shell.execute_reply.started":"2024-03-17T21:24:57.613978Z","shell.execute_reply":"2024-03-17T21:24:57.621666Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:24:59.814182Z","iopub.execute_input":"2024-03-17T21:24:59.815427Z","iopub.status.idle":"2024-03-17T21:24:59.820421Z","shell.execute_reply.started":"2024-03-17T21:24:59.815381Z","shell.execute_reply":"2024-03-17T21:24:59.819380Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns(\n    dataset[\"train\"].column_names\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:25:01.488757Z","iopub.execute_input":"2024-03-17T21:25:01.489781Z","iopub.status.idle":"2024-03-17T21:25:01.500055Z","shell.execute_reply.started":"2024-03-17T21:25:01.489737Z","shell.execute_reply":"2024-03-17T21:25:01.499158Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"features = [tokenized_datasets[\"train\"][i] for i in range(2)]\ndata_collator(features)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:25:03.193632Z","iopub.execute_input":"2024-03-17T21:25:03.194014Z","iopub.status.idle":"2024-03-17T21:25:03.281623Z","shell.execute_reply.started":"2024-03-17T21:25:03.193988Z","shell.execute_reply":"2024-03-17T21:25:03.280669Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[   417, 204350,   7898, 110348,  13701,   2739, 117860,   1560,  80303,\n            718, 229015,   4256, 227491,    135, 138839,   1551,   5785, 200218,\n            559,      4,     49,   7904,   2696,   3318, 207311,     59,  13192,\n          17272,   9296,    407,  61789, 141313,     89,      6,   3737,   1951,\n              4,  41346,      4, 212814,    718,  35734,     77,  33103,      4,\n          83694, 193182,  97836,  11974,  38664,    227,      6,  53058, 111346,\n           5866,   2739, 117860,   1560, 124476,     59,  18531,    105,  10327,\n           8571,    698,      5,   4531, 143675,      4,    414,     49,   7904,\n          82427, 168730,  19036,   5124,  16641,  25455, 110112,  26435,     49,\n         147332,      4,   7176,      4,     49,   8914,  44515,      4,  22263,\n           2033,    547,    407,     77, 145995,  31224,  11981,  13345,  71302,\n              5,     44,  67319,  13962,     49,   2660,      4,    414, 212814,\n           5434,     77,  54145,      4,  14239,    414,     77,  54145,  75586,\n         204350,   8809,  51452,      4,  14239,    414,   4988,  75586,  20803,\n          43475,     35,  82417,   1730,     61,    424,  31238,  45306, 204350,\n          25455,     29,  20724,   4468,     35,     49,    804, 105489,  20151,\n              2, 250004,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1],\n        [231683,    559,  41322,   2637,  33364,  61888,      9, 106814,    227,\n            129,    326,    415,   3635,     35,  60050, 115987,    105,  61888,\n          11312,      4,  79015,     89,  36690,  45961,     49,  79171,      9,\n          56162,    103,  31303,     59, 104000,     35, 238578, 172729,  58529,\n            559,     35,  23214, 164263,  17880,   1196, 223957,    804,  94078,\n          21678,  18531,  20733,   1323,   7343,      5,    423,  35185,     49,\n          72181,  52400,   7898,  36080,   2188, 203619,  25768,   1041,  48626,\n             44, 107371,   2042,     35, 139135,    830,     49,  33763, 220116,\n          12635, 216045,     35,  13391, 117453,  80317,  38140,  43398,  82071,\n           1835,      4,  85096,    312,    969, 150804,    130, 202624,   2493,\n            419,  41805,   2042,      4,  12375,   1730,    135,      6, 107098,\n          67627,    827,  90216,  94788,     89,      5, 158302,  22263,   2297,\n             29, 108629,    736,   1394,   5532, 206096,  40976,   3858, 179229,\n            312,  15206, 141770,    559,  75674,  43760,    103,    245,  74874,\n             59,      5,   3858, 179229,    312,  15206, 141770,    559,  75674,\n          43760,    103,    245,  74874,     59,     61, 100959,    212, 149890,\n           4476,  25254, 126487,  33583,     61,  55664,   1281,   8568,     35,\n             61,  52353,   7846, 162963,    743,  14806,    424,  33430, 126504,\n           1196,  51012,  58110,    135,   7204, 188557,      4,  90402, 124234,\n         173383,     49,   8568,      5,   5188,   3920, 206096,     59,     29,\n          79171,      9,  38401,   1993, 133160,  73044, 185537,  31303,     59,\n         225029,     35,  23214, 211424,    695,  66104,   1114, 141770,     59,\n          43760,    103,    245,  74874,     59,      4, 172829,   2192,      6,\n          50786,  15279, 197604,   8568,      4, 199141, 141770,     59, 157456,\n          74874,     59,      5, 193677,  37984,  59392,    591,  36421,    105,\n          34496,     49, 164411,   1993,  82493,  32533,  39255, 183795,     59,\n            969,  31026,    130, 169460,     59,   7931,  28651,   1120,      4,\n            252,     49,    779,  11360,  11519,     44,  70659,  63162, 109779,\n            227,     58, 204347, 172729,  43450,    222, 117766,  13110,  12635,\n         183795,    969,  31026,    130, 172829,   1270, 124972,     59,   8568,\n           6871,    415,  63149,   3681,    226,  12757,   3635,    244,    205,\n              4,     49, 205932,     49,  27135,   2637, 107286,   2354,  73931,\n          35185, 164261, 195206,     59, 157457,  13756,    336,    547,    551,\n          17845,    640,      4,  14925,  32529,    135,    255,  25734,  18372,\n          11989,   1269,  24130,  35308,    546, 112555, 210551,     59,     49,\n           1087,  66505,  29632,    227,     49,  52429,      4,    252,  14805,\n            129, 174866,     59,     49, 163777,      4,   4851, 237748,     59,\n             29,   7762,   8688,   2172,  24239,    103, 194848,      5,     44,\n           2354,      6, 186143,    616,  35185,     29,  60050,    105, 240467,\n          41374,    312,   1670,   2457,   7246,  49564,    447,   5719,  58877,\n            526,    529,  40064,    718,   7179,    226,  13449,      4,   4562,\n           8618,   7878, 216784,  10962,    222,   5004,    135, 144451,   1595,\n         235955,  55994, 183795,    419,     35,   8898,  68197,   4560,  42754,\n            336,      5,   4531, 111529,      4,    414,  94687,    105, 130239,\n           5058,    969,  15919,   3844,  91012,  17880,   1196,  39084,      4,\n          70583, 156721,   1584,     49,  86632,  42393,  35308,  63789, 154381,\n          14576,  98361,     35,  60900,  56102,      4,   4851,    591,    312,\n          33364,  26017,    227,      5,  21076, 107857,  45474,     58,    135,\n            811, 121973,    130,  91728,  12780,  15057, 216045,    559,    518,\n            210,  12780,  15057,  28203,  29751,   3318, 115350,  39331,     49,\n              6, 186143,    702,  13528,  35185,      2, 250004]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1]]), 'labels': tensor([[   417, 204350,   7898, 110348,  13701,   2739, 117860,   1560,  80303,\n            718, 229015,   4256, 227491,    135, 138839,   1551,   5785, 200218,\n            559,      4,     49,   7904,   2696,   3318, 207311,     59,  13192,\n          17272,   9296,    407,  61789, 141313,     89,      6,   3737,   1951,\n              4,  41346,      4, 212814,    718,  35734,     77,  33103,      4,\n          83694,  11974,  38664,    227,      6,  53058, 111346,   5866,   2739,\n         117860,   1560, 124476,     59,  18531,    105,  10327,   8571,    698,\n              5,   4531, 143675,      4,    414,     49,   7904,  82427, 168730,\n          19036,   5124,  16641,  25455, 110112,  26435,     49, 147332,      4,\n           7176,      4,     49,   8914,  44515,      4,  22263,   2033,    547,\n            407,     77, 145995,  31224,  11981,  13345,  71302,      5,      2,\n         250004,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n           -100,   -100],\n        [   417,  72181,  52400,   7898,  36080,   2188,    423,  35185, 203619,\n          25768,   1041,  48626,     94, 107371,   2042,     35, 139135,   1339,\n             49,  33763, 220116,  12635, 216045,     35,  13391, 117453,  80317,\n          38140,  43398,  82071,   1835,      4,  85096,    312,    969, 150804,\n            130, 202624,   2493,    419,  41805,   2042,      4,  12375,   1730,\n            135,      6, 107098,  67627,    827,  90216,  94788,     89,      5,\n         193677,  37984,  59392,    591,  36421,    105,  34496,     49, 164411,\n           1993,  82493,  32533,  39255, 183795,     59,    969,  31026,    130,\n         169460,     59,   7931,  28651,   1120,      4,    252,     49,    779,\n          11360,  11519,     94,  70659,  63162, 109779,    227,    167, 204347,\n         172729,  43450,    222, 117766,  13110,  12635, 183795,    969,  31026,\n            130, 172829,   1270, 124972,     59,   8568,   6871,    415,  63149,\n           3681,    226,  12757,   3635,    244,    205,      5,   2354,      6,\n         186143, 115350,    591,    312,  33364,  26017,    227,  91728,  12780,\n          15057, 216045,    559,    518,    210,  12780,  15057,  28203,  29751,\n              5,   5188,   3920,  79015,     59, 157457,  13756,    336,    547,\n            551,  17845,    640,      4,  14925,  32529,    135,    255,  25734,\n          18372,  11989,   1269,  24130,  35308,    546, 112555, 210551,     59,\n             49,   1087,  66505,  29632,    227,     49,  52429,      4,    252,\n          14805,    129, 174866,     59,     49, 163777,      4,   4851, 237748,\n             59,     29,   7762,   8688,   2172,  24239,    103, 194848,      5,\n              2, 250004]]), 'decoder_input_ids': tensor([[250004,    417, 204350,   7898, 110348,  13701,   2739, 117860,   1560,\n          80303,    718, 229015,   4256, 227491,    135, 138839,   1551,   5785,\n         200218,    559,      4,     49,   7904,   2696,   3318, 207311,     59,\n          13192,  17272,   9296,    407,  61789, 141313,     89,      6,   3737,\n           1951,      4,  41346,      4, 212814,    718,  35734,     77,  33103,\n              4,  83694,  11974,  38664,    227,      6,  53058, 111346,   5866,\n           2739, 117860,   1560, 124476,     59,  18531,    105,  10327,   8571,\n            698,      5,   4531, 143675,      4,    414,     49,   7904,  82427,\n         168730,  19036,   5124,  16641,  25455, 110112,  26435,     49, 147332,\n              4,   7176,      4,     49,   8914,  44515,      4,  22263,   2033,\n            547,    407,     77, 145995,  31224,  11981,  13345,  71302,      5,\n              2, 250004,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1],\n        [250004,    417,  72181,  52400,   7898,  36080,   2188,    423,  35185,\n         203619,  25768,   1041,  48626,     94, 107371,   2042,     35, 139135,\n           1339,     49,  33763, 220116,  12635, 216045,     35,  13391, 117453,\n          80317,  38140,  43398,  82071,   1835,      4,  85096,    312,    969,\n         150804,    130, 202624,   2493,    419,  41805,   2042,      4,  12375,\n           1730,    135,      6, 107098,  67627,    827,  90216,  94788,     89,\n              5, 193677,  37984,  59392,    591,  36421,    105,  34496,     49,\n         164411,   1993,  82493,  32533,  39255, 183795,     59,    969,  31026,\n            130, 169460,     59,   7931,  28651,   1120,      4,    252,     49,\n            779,  11360,  11519,     94,  70659,  63162, 109779,    227,    167,\n         204347, 172729,  43450,    222, 117766,  13110,  12635, 183795,    969,\n          31026,    130, 172829,   1270, 124972,     59,   8568,   6871,    415,\n          63149,   3681,    226,  12757,   3635,    244,    205,      5,   2354,\n              6, 186143, 115350,    591,    312,  33364,  26017,    227,  91728,\n          12780,  15057, 216045,    559,    518,    210,  12780,  15057,  28203,\n          29751,      5,   5188,   3920,  79015,     59, 157457,  13756,    336,\n            547,    551,  17845,    640,      4,  14925,  32529,    135,    255,\n          25734,  18372,  11989,   1269,  24130,  35308,    546, 112555, 210551,\n             59,     49,   1087,  66505,  29632,    227,     49,  52429,      4,\n            252,  14805,    129, 174866,     59,     49, 163777,      4,   4851,\n         237748,     59,     29,   7762,   8688,   2172,  24239,    103, 194848,\n              5,      2]])}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:25:08.051514Z","iopub.execute_input":"2024-03-17T21:25:08.052302Z","iopub.status.idle":"2024-03-17T21:25:11.934362Z","shell.execute_reply.started":"2024-03-17T21:25:08.052268Z","shell.execute_reply":"2024-03-17T21:25:11.933382Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:25:21.349777Z","iopub.execute_input":"2024-03-17T21:25:21.350529Z","iopub.status.idle":"2024-03-17T21:39:51.855668Z","shell.execute_reply.started":"2024-03-17T21:25:21.350494Z","shell.execute_reply":"2024-03-17T21:39:51.854631Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240317_212530-cxrcb5n7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/solonar/huggingface/runs/cxrcb5n7' target=\"_blank\">denim-thunder-16</a></strong> to <a href='https://wandb.ai/solonar/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/solonar/huggingface' target=\"_blank\">https://wandb.ai/solonar/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/solonar/huggingface/runs/cxrcb5n7' target=\"_blank\">https://wandb.ai/solonar/huggingface/runs/cxrcb5n7</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16/16 13:08, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.637800</td>\n      <td>0.261617</td>\n      <td>27.777800</td>\n      <td>26.190500</td>\n      <td>27.777800</td>\n      <td>27.777800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.269800</td>\n      <td>0.258618</td>\n      <td>25.000000</td>\n      <td>16.666700</td>\n      <td>20.833300</td>\n      <td>25.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=16, training_loss=0.45384034514427185, metrics={'train_runtime': 870.0691, 'train_samples_per_second': 0.055, 'train_steps_per_second': 0.018, 'total_flos': 90761060763648.0, 'train_loss': 0.45384034514427185, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:40:22.966107Z","iopub.execute_input":"2024-03-17T21:40:22.967035Z","iopub.status.idle":"2024-03-17T21:43:33.382286Z","shell.execute_reply.started":"2024-03-17T21:40:22.967001Z","shell.execute_reply":"2024-03-17T21:43:33.381182Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 01:48]\n    </div>\n    "},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.25861817598342896,\n 'eval_rouge1': 25.0,\n 'eval_rouge2': 16.6667,\n 'eval_rougeL': 20.8333,\n 'eval_rougeLsum': 25.0,\n 'eval_runtime': 190.4019,\n 'eval_samples_per_second': 0.032,\n 'eval_steps_per_second': 0.011,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:46:44.553259Z","iopub.execute_input":"2024-03-17T21:46:44.554263Z","iopub.status.idle":"2024-03-17T21:48:17.070282Z","shell.execute_reply.started":"2024-03-17T21:46:44.554218Z","shell.execute_reply":"2024-03-17T21:48:17.068219Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'num_beams': 5, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b5e66f9a6f453db760f3f128473d16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1710711813.1808ed8ca354.35.1:   0%|          | 0.00/553 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb58c24244f644eeaf6ffa3934d295fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4198fdafc1f470298ff7b5be7707bb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8d95af8f61445009743d0878ec840d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1710710721.1808ed8ca354.35.0:   0%|          | 0.00/7.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e737976e6440dfb6bd9af49e82f54e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b8953d7cbab45f280a3b8ec8feaa49e"}},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/solonarr/1-finetuned-amazon-en-es/commit/4c621fcc7317a8654a461b3737c2e3bfaf357928', commit_message='Training complete', commit_description='', oid='4c621fcc7317a8654a461b3737c2e3bfaf357928', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"# training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n# model = MBartForConditionalGeneration.from_pretrained(checkpoint)\n\n# trainer = Trainer(\n#     model,\n#     training_args,\n#     train_dataset=tokenized_datasets[\"train\"],\n#     eval_dataset=tokenized_datasets[\"test\"],\n#     data_collator=data_collator,\n#     tokenizer=tokenizer,\n#     compute_metrics=compute_metrics,\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import Seq2SeqTrainingArguments\n\n# batch_size = 8\n# num_train_epochs = 8\n# # Show the training loss with every epoch\n# logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n# model_name = model_checkpoint.split(\"/\")[-1]\n\n# args = Seq2SeqTrainingArguments(\n#     output_dir=f\"{model_name}-finetuned-amazon-en-es\",\n#     evaluation_strategy=\"epoch\",\n#     learning_rate=5.6e-5,\n#     per_device_train_batch_size=batch_size,\n#     per_device_eval_batch_size=batch_size,\n#     weight_decay=0.01,\n#     save_total_limit=3,\n#     num_train_epochs=num_train_epochs,\n#     predict_with_generate=True,\n#     logging_steps=logging_steps,\n#     push_to_hub=True,\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}